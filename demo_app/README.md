# 強化学習オセロエージェント　デモアプリ

## 環境構築(uv使用)

```bash
uv sync
```

- Windows環境ではGPU対応のPyTorchをuvでインストールできないため、`pip`で別途インストールする

## 実行

```bash
# uvの場合
uv run main.py
```

```bash
# pipの場合
python main.py
```

## 実装内容

## ディレクトリ構成（予定）

```text
demo_app/
├── README.md
├── main.py                  # エントリーポイント（Tkinter起動）
├── app/
│   ├── __init__.py
│   ├── ui/
│   │   ├── __init__.py
│   │   ├── home_view.py           # ホーム画面（モード選択、エージェント選択）
│   │   ├── agent_vs_human_view.py # 人間 vs エージェント画面
│   │   └── agent_vs_agent_view.py # エージェント同士対戦画面
│   ├── controllers/
│   │   ├── __init__.py
│   │   ├── game_controller.py     # ボード状態管理、ターン制御
│   │   └── agent_loader.py        # 各種エージェントの生成・初期化
│   ├── agents/
│   │   ├── __init__.py
│   │   ├── random_agent.py
│   │   ├── dqn_agent.py
│   │   ├── bc_agent.py
│   │   └── mcts_nn_agent.py
│   ├── game/
│   │   ├── __init__.py
│   │   ├── board.py                # 盤面表現・合法手計算
│   │   └── renderer.py             # Tkinterキャンバス描画
│   └── utils/
│       ├── __init__.py
│       └── timers.py               # インターバル制御用タイマー
└── assets/
    └── images/                     # アイコン・駒画像など
```

## アプリ概要

- **ホーム画面**: 「人間 vs 強化学習エージェント」「エージェント vs エージェント」の2モードから選択。各モードで対戦させるエージェントをドロップダウンなどで決定する。
- **人間 vs 強化学習エージェント**: ユーザーが黒/白を選択し、ターンごとに手を入力。エージェントは現在の局面から即時に手を返す。
- **エージェント vs エージェント**: 2体のエージェントを選択。ゲーム開始後は1秒ごとに自動で手を選択し、盤面を更新して進行する。
- **共通仕様**: 対局の進行状況、合法手ハイライト、過去手のログ表示（簡易）を予定。

## 対応エージェント

- **ランダム**: 合法手の中から一様ランダムに手を選択。
- **DQN**: 既存のDQNポリシーを呼び出して推論。
- **BC模倣学習**: 教師データに基づく模倣学習済みモデルを利用。
- **MCTS+NN**: 既存のニューラルネットワーク評価値を用いたモンテカルロ木探索。