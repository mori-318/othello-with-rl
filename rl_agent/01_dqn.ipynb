{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de3e60d",
   "metadata": {},
   "source": [
    "## DQNでエージェントを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef50696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "from collections import deque\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ee691",
   "metadata": {},
   "source": [
    "## オセロ環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca48b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opponent(c):\n",
    "    \"\"\"現在のプレイヤーの相手を返す\"\"\"\n",
    "    return -c\n",
    "\n",
    "EMPTY, BLACK, WHITE = 0, 1, -1\n",
    "DIRECTIONS = [(-1,-1),(-1,0),(-1,1),(0,-1),(0,1),(1,-1),(1,0),(1,1)]\n",
    "\n",
    "class Othello:\n",
    "    def __init__(self):\n",
    "        self.board = [[EMPTY for _ in range(8)] for _ in range(8)]\n",
    "        self.board[3][3] = self.board[4][4] = WHITE\n",
    "        self.board[3][4] = self.board[4][3] = BLACK\n",
    "        self.player = BLACK\n",
    "\n",
    "    def clone(self):\n",
    "        \"\"\"盤面をコピーして新しいインスタンスを返す\"\"\"\n",
    "        g = Othello()\n",
    "        g.board = [row[:] for row in self.board]\n",
    "        g.player = self.player\n",
    "        return g\n",
    "\n",
    "    def inside(self, r, c):\n",
    "        \"\"\"\n",
    "        盤面の範囲内かを返す\n",
    "        Args:\n",
    "            r (int): 行\n",
    "            c (int): 列\n",
    "        Returns:\n",
    "            bool: 盤面の範囲内か\n",
    "        \"\"\"\n",
    "        return 0 <= r < 8 and 0 <= c < 8\n",
    "\n",
    "    def legal_moves(self, player=None) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        合法手を返す\n",
    "        Args:\n",
    "            player (int, optional): プレイヤーの色.指定しない場合は現在のプレイヤーを返す\n",
    "        Returns:\n",
    "            List[Tuple[int, int]]: 合法手のリスト\n",
    "        \"\"\"\n",
    "        if player is None:\n",
    "            player = self.player\n",
    "        moves = []\n",
    "        for r in range(8):\n",
    "            for c in range(8):\n",
    "                if self.board[r][c] != EMPTY:  # 空白でない場合は合法手ではない\n",
    "                    continue\n",
    "                if self._would_flip(r, c, player):  # 石をひっくり返せる場合は合法手\n",
    "                    moves.append((r, c))\n",
    "        return moves\n",
    "\n",
    "    def _would_flip(self, r, c, player) -> bool:\n",
    "        \"\"\"\n",
    "        石をひっくり返せるかを返す\n",
    "        Args:\n",
    "            r (int): 行\n",
    "            c (int): 列\n",
    "            player (int): プレイヤーの色\n",
    "        Returns:\n",
    "            bool: 石をひっくり返せるか\n",
    "        \"\"\"\n",
    "        if self.board[r][c] != EMPTY:  # 空白でない場合は石をひっくり返せない\n",
    "            return False\n",
    "        for dr, dc in DIRECTIONS:\n",
    "            rr, cc = r + dr, c + dc\n",
    "            seen_opp = False  # 相手の石を一度見たか\n",
    "            while self.inside(rr, cc) and self.board[rr][cc] == opponent(player):  # 盤面の範囲内か & 相手の石が置かれている場所か\n",
    "                seen_opp = True\n",
    "                rr += dr; cc += dc\n",
    "            if seen_opp and self.inside(rr, cc) and self.board[rr][cc] == player:  # 相手の石を一度見たか & 盤面の範囲内か & 自分の石をみたか\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def play(self, r, c, player=None):\n",
    "        \"\"\"\n",
    "        石を置く & 石をひっくり返す\n",
    "        Args:\n",
    "            r (int): 行\n",
    "            c (int): 列\n",
    "            player (int, optional): プレイヤーの色.指定しない場合は現在のプレイヤーを返す\n",
    "        \"\"\"\n",
    "        if player is None:\n",
    "            player = self.player\n",
    "        assert self.board[r][c] == EMPTY  # 空白でない場合は石を置くことができない\n",
    "        flipped = []\n",
    "        for dr, dc in DIRECTIONS:\n",
    "            line = []\n",
    "            rr, cc = r + dr, c + dc\n",
    "            while self.inside(rr,cc) and self.board[rr][cc] == opponent(player):  # 盤面の範囲内か & 相手の石が置かれている場所か\n",
    "                line.append((rr,cc))  # 石をひっくり返す場所を追加\n",
    "                rr += dr; cc += dc\n",
    "            if line and self.inside(rr,cc) and self.board[rr][cc] == player:  # 石をひっくり返す場所が存在 & 盤面の範囲内か & 自分の石をみたか\n",
    "                flipped.extend(line)  # 石をひっくり返す場所を追加\n",
    "        if not flipped:  # 石をひっくり返す場所が存在しない場合は不正な手\n",
    "            raise ValueError(\"Illegal move\")\n",
    "        self.board[r][c] = player\n",
    "        for rr,cc in flipped:  # 石をひっくり返す\n",
    "            self.board[rr][cc] = player\n",
    "        self.player = opponent(player)\n",
    "        # 現在のプレイヤーが合法手がない場合は相手の番\n",
    "        if not self.legal_moves(self.player):\n",
    "            self.player = opponent(self.player)\n",
    "\n",
    "    def is_terminal(self) -> bool:\n",
    "        \"\"\"\n",
    "        終局かを返す\n",
    "        Returns:\n",
    "            bool: 終局か\n",
    "        \"\"\"\n",
    "        if self.legal_moves(BLACK): return False\n",
    "        if self.legal_moves(WHITE): return False\n",
    "        return True\n",
    "\n",
    "    def game_score(self) -> int:\n",
    "        \"\"\"\n",
    "        黒が+1, 白が-1としてスコアを計算\n",
    "        Returns:\n",
    "            int: スコア\n",
    "        \"\"\"\n",
    "        s = 0\n",
    "        for r in range(8):\n",
    "            for c in range(8):\n",
    "                s += self.board[r][c]\n",
    "        return s\n",
    "\n",
    "    def winner(self) -> int:\n",
    "        s = self.game_score()\n",
    "        return BLACK if s > 0 else WHITE if s < 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0093b77d",
   "metadata": {},
   "source": [
    "### 報酬設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ab1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reward:\n",
    "    def __init__(\n",
    "        self, player,\n",
    "        weight_corner=1.0, weight_dangerous=-1.2,\n",
    "        weight_mobility=1.0, weight_frontier=-0.6\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            player (int): 手番\n",
    "            weight_corner (float): 角の重み\n",
    "            weight_dangerous (float): 危険な場所の重み\n",
    "            weight_mobility (float): モビリティの重み\n",
    "            weight_frontier (float): フロンティアの重み\n",
    "        \"\"\"\n",
    "        self.player = player\n",
    "        self.weight_corner = weight_corner\n",
    "        self.weight_dangerous = weight_dangerous\n",
    "        self.weight_mobility = weight_mobility\n",
    "        self.weight_frontier = weight_frontier\n",
    "\n",
    "    def get_reward(self, env: Othello):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            env (Othello): オセロ環境\n",
    "        Returns:\n",
    "            float: 報酬\n",
    "        \"\"\"\n",
    "        if self._is_terminal(env):\n",
    "            pc, oc = self._count_stones(env)\n",
    "            # 勝敗ベースの終局報酬\n",
    "            return 1.0 if pc > oc else (-1.0 if pc < oc else 0.0)\n",
    "\n",
    "        phase = self._get_game_phase(env)\n",
    "\n",
    "        # 角\n",
    "        my_corner, op_corner = self._count_corner_stones(env)\n",
    "        corner_term = self._safe_ratio(my_corner - op_corner, max(1, my_corner + op_corner))\n",
    "\n",
    "        # 危険（X/C だけを見る）\n",
    "        my_dang, op_dang = self._count_xc_danger(env)\n",
    "        danger_term = self._safe_ratio(my_dang - op_dang, max(1, my_dang + op_dang))\n",
    "\n",
    "        # モビリティ（相対値）\n",
    "        my_mob = len(env.legal_moves(self.player))\n",
    "        op_mob = len(env.legal_moves(opponent(self.player)))\n",
    "        mobility_term = self._safe_ratio(my_mob - op_mob, max(1, my_mob + op_mob))\n",
    "\n",
    "        # フロンティア（多いほど悪い → 符号反転）\n",
    "        my_front, op_front = self._count_frontier(env)\n",
    "        frontier_term = self._safe_ratio(my_front - op_front, max(1, my_front + op_front))\n",
    "\n",
    "        if phase in (0, 1):  # 序・中盤\n",
    "            reward = (\n",
    "                self.weight_mobility * mobility_term +\n",
    "                self.weight_corner   * corner_term +\n",
    "                self.weight_dangerous * danger_term +\n",
    "                self.weight_frontier * frontier_term\n",
    "            )\n",
    "        else:  # 後盤（石差を薄く採用）\n",
    "            pc, oc = self._count_stones(env)\n",
    "            disc_diff_term = self._safe_ratio(pc - oc, max(1, pc + oc))\n",
    "            reward = 0.5 * (self.weight_corner * corner_term) \\\n",
    "                   + 0.3 * (self.weight_mobility * mobility_term) \\\n",
    "                   + 0.2 * disc_diff_term\n",
    "\n",
    "        # クリップ\n",
    "        return max(-1.0, min(1.0, reward))\n",
    "\n",
    "    # ---------- 補助 ----------\n",
    "    def _is_terminal(self, env: Othello):\n",
    "        return (len(env.legal_moves(self.player)) == 0 and\n",
    "                len(env.legal_moves(opponent(self.player))) == 0)\n",
    "\n",
    "    def _safe_ratio(self, num, den):  # [-1,1] 目安\n",
    "        return num / den if den != 0 else 0.0\n",
    "\n",
    "    def _get_game_phase(self, env: Othello):\n",
    "        pc, oc = self._count_stones(env)\n",
    "        n = pc + oc\n",
    "        if n <= 20:  # 序盤\n",
    "            return 0\n",
    "        elif n <= 45:  # 中盤\n",
    "            return 1\n",
    "        else:  # 後盤\n",
    "            return 2\n",
    "\n",
    "    def _count_stones(self, env: Othello):\n",
    "        pc = oc = 0\n",
    "        for r in range(8):\n",
    "            for c in range(8):\n",
    "                if env.board[r][c] == self.player: pc += 1\n",
    "                elif env.board[r][c] == opponent(self.player): oc += 1\n",
    "        return pc, oc\n",
    "\n",
    "    def _count_corner_stones(self, env: Othello):\n",
    "        corners = [(0,0),(0,7),(7,0),(7,7)]\n",
    "        pc = oc = 0\n",
    "        for r,c in corners:\n",
    "            if env.board[r][c] == self.player: pc += 1\n",
    "            elif env.board[r][c] == opponent(self.player): oc += 1\n",
    "        return pc, oc\n",
    "\n",
    "    def _count_xc_danger(self, env: Othello):\n",
    "        # 角と対応する X/C だけを見る\n",
    "        corners = [(0,0),(0,7),(7,0),(7,7)]\n",
    "        X      = [(1,1),(1,6),(6,1),(6,6)]\n",
    "        C      = [(0,1),(1,0),(0,6),(1,7),(6,0),(7,1),(6,7),(7,6)]\n",
    "        pc = oc = 0\n",
    "        # X\n",
    "        for (xr,xc),(cr,cc) in zip(X,corners):\n",
    "            if env.board[cr][cc] == EMPTY:\n",
    "                if env.board[xr][xc] == self.player: pc += 1\n",
    "                elif env.board[xr][xc] == opponent(self.player): oc += 1\n",
    "        # C（対応角が空なら危険）\n",
    "        for r,c in C:\n",
    "            cr = 0 if r in (0,1) else 7\n",
    "            cc = 0 if c in (0,1) else 7\n",
    "            if env.board[cr][cc] == EMPTY:\n",
    "                if env.board[r][c] == self.player: pc += 1\n",
    "                elif env.board[r][c] == opponent(self.player): oc += 1\n",
    "        return pc, oc\n",
    "\n",
    "    def _count_frontier(self, env: Othello):\n",
    "        pc = oc = 0\n",
    "        for r in range(8):\n",
    "            for c in range(8):\n",
    "                cell = env.board[r][c]\n",
    "                if cell == EMPTY:\n",
    "                    continue\n",
    "                # 隣に空きがあればフロンティア\n",
    "                frontier = any(\n",
    "                    0 <= r+dr < 8 and 0 <= c+dc < 8 and env.board[r+dr][c+dc] == EMPTY\n",
    "                    for dr in (-1,0,1) for dc in (-1,0,1) if dr or dc\n",
    "                )\n",
    "                if frontier:\n",
    "                    if cell == self.player: pc += 1\n",
    "                    elif cell == opponent(self.player): oc += 1\n",
    "        return pc, oc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d3102",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7f4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "\n",
    "\n",
    "# オセロクラスの簡単な初期化テスト\n",
    "def test_othello_init():\n",
    "    env = Othello()\n",
    "\n",
    "    # ボードのサイズ\n",
    "    assert len(env.board) == 8\n",
    "    assert all(len(row) == 8 for row in env.board)\n",
    "\n",
    "    # 中心マスの初期配置\n",
    "    assert env.board[3][3] == -1\n",
    "    assert env.board[3][4] == 1\n",
    "    assert env.board[4][3] == 1\n",
    "    assert env.board[4][4] == -1\n",
    "\n",
    "    # 中心ます以外は0\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            if i == 3 and j in (3, 4):\n",
    "                continue\n",
    "            if i == 4 and j in (3, 4):\n",
    "                continue\n",
    "            assert env.board[i][j] == 0\n",
    "\n",
    "    # 初手は黒（1）の番\n",
    "    assert env.player == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afdc381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -qq\n",
    "\n",
    "BLACK = 1\n",
    "WHITE = -1\n",
    "\n",
    "# Rewardクラスのテスト\n",
    "class TestReward:\n",
    "    def setup_method(self):\n",
    "        self.env = Othello()\n",
    "        self.reward_black = Reward(BLACK)\n",
    "        self.reward_white = Reward(WHITE)\n",
    "\n",
    "    def test_init(self):\n",
    "        assert self.reward_black.player == BLACK\n",
    "        assert self.reward_white.player == WHITE\n",
    "\n",
    "    def test_terminal_black_win(self):\n",
    "        env = Othello()\n",
    "        env.board = [[BLACK] * 8 for _ in range(8)]\n",
    "\n",
    "        assert self.reward_black.get_reward(env) == 1\n",
    "        assert self.reward_white.get_reward(env) == -1\n",
    "\n",
    "    def test_terminal_draw(self):\n",
    "        env = Othello()\n",
    "        env.board = [[BLACK if (i + j) % 2 else WHITE for j in range(8)] for i in range(8)]\n",
    "\n",
    "        assert self.reward_black.get_reward(env) == 0\n",
    "        assert self.reward_white.get_reward(env) == 0\n",
    "\n",
    "    def test_early_phase(self):\n",
    "        env = Othello()\n",
    "\n",
    "        # 序盤かを確認\n",
    "        assert self.reward_black._get_game_phase(env) == 0\n",
    "\n",
    "        # 初期配置パターンでの報酬を確認\n",
    "        reward_black = self.reward_black.get_reward(env)\n",
    "        reward_white = self.reward_white.get_reward(env)\n",
    "        assert abs(reward_black) < 1e-5\n",
    "        assert abs(reward_white) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af76fb",
   "metadata": {},
   "source": [
    "## DQNのネットワーク定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba46330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=in_channels,\n",
    "            kernel_size=3, padding=1, groups=in_channels, bias=False,\n",
    "        )\n",
    "        self.pw = nn.Conv2d(\n",
    "            in_channels=in_channels, out_channels=out_channels,\n",
    "            kernel_size=1, bias=False,\n",
    "        )\n",
    "        self.gn = nn.GroupNorm(num_groups=1, num_channels=out_channels)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x)\n",
    "        x = self.pw(x)\n",
    "        x = self.gn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=8,\n",
    "                kernel_size=3, padding=1, bias=False,\n",
    "            ),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.block1 = DSConv(in_channels=8, out_channels=8)\n",
    "        self.block2 = DSConv(in_channels=8, out_channels=8)\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=8, out_features=64),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "        self.head = nn.Linear(in_features=64, out_features=65)  # 65番目は、パスの行動\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc003cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 65])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DQN                                      [1, 65]                   --\n",
       "├─Sequential: 1-1                        [1, 8, 8, 8]              --\n",
       "│    └─Conv2d: 2-1                       [1, 8, 8, 8]              72\n",
       "│    └─SiLU: 2-2                         [1, 8, 8, 8]              --\n",
       "├─DSConv: 1-2                            [1, 8, 8, 8]              --\n",
       "│    └─Conv2d: 2-3                       [1, 8, 8, 8]              72\n",
       "│    └─Conv2d: 2-4                       [1, 8, 8, 8]              64\n",
       "│    └─GroupNorm: 2-5                    [1, 8, 8, 8]              16\n",
       "│    └─SiLU: 2-6                         [1, 8, 8, 8]              --\n",
       "├─DSConv: 1-3                            [1, 8, 8, 8]              --\n",
       "│    └─Conv2d: 2-7                       [1, 8, 8, 8]              72\n",
       "│    └─Conv2d: 2-8                       [1, 8, 8, 8]              64\n",
       "│    └─GroupNorm: 2-9                    [1, 8, 8, 8]              16\n",
       "│    └─SiLU: 2-10                        [1, 8, 8, 8]              --\n",
       "├─AdaptiveAvgPool2d: 1-4                 [1, 8, 1, 1]              --\n",
       "├─Sequential: 1-5                        [1, 64]                   --\n",
       "│    └─Flatten: 2-11                     [1, 8]                    --\n",
       "│    └─Linear: 2-12                      [1, 64]                   576\n",
       "│    └─SiLU: 2-13                        [1, 64]                   --\n",
       "├─Linear: 1-6                            [1, 65]                   4,225\n",
       "==========================================================================================\n",
       "Total params: 5,177\n",
       "Trainable params: 5,177\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.03\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# アーキテクチャのテスト\n",
    "dqn = DQN()\n",
    "dummy_input = torch.zeros((1, 1, 8, 8))\n",
    "print(dqn(dummy_input).shape)\n",
    "torchinfo.summary(dqn, (1, 1, 8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00283a17",
   "metadata": {},
   "source": [
    "## DQNの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb3813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, memory_size):\n",
    "        self.memory_size = memory_size\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "\n",
    "    def append(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df06871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class TrainDoubleDQN:\n",
    "    \"\"\"\n",
    "    Othello 用 Double DQN 学習クラス\n",
    "    - Double DQN: a' = argmax_a Q_online(s', a), target = r + γ (1-done) Q_target(s', a')\n",
    "    - 行動 0..63 が盤面、64 がパス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dqn,  # nn.Module 互換 (B,1,8,8) -> (B,65)\n",
    "        gamma: float = 0.99,\n",
    "        lr: float = 1e-3,\n",
    "        batch_size: int = 64,\n",
    "        init_memory_size: int = 5000,\n",
    "        memory_size: int = 50000,\n",
    "        target_update_freq: int = 1000,   # ハード更新の頻度（steps）\n",
    "        tau: float = 0.0,                 # >0 で Polyak (soft) 更新。0 ならハード更新。\n",
    "        num_episodes: int = 1000,\n",
    "        max_steps_per_episode: int = 200,\n",
    "        train_freq: int = 1,              # 何ステップに一回アップデートするか\n",
    "        gradient_steps: int = 1,          # 1 回の学習トリガで何回更新するか\n",
    "        learning_starts: int = 1000,      # これ未満は収集のみ\n",
    "        epsilon_start: float = 1.0,\n",
    "        epsilon_end: float = 0.05,\n",
    "        epsilon_decay_steps: int = 30000, # ステップ単位で減衰\n",
    "        seed: int = 42,\n",
    "        device: Optional[torch.device] = None,\n",
    "        ReplayBufferCls=None,             # 既存の ReplayBuffer を差す\n",
    "    ):\n",
    "        assert ReplayBufferCls is not None, \"ReplayBufferCls を渡してください（既存の ReplayBuffer クラス）\"\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # RNG 固定\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        self.dqn = dqn.to(self.device)\n",
    "        self.target_dqn = copy.deepcopy(dqn).to(self.device)\n",
    "        self.target_dqn.eval()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters(), lr=lr)\n",
    "        self.loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.init_memory_size = init_memory_size\n",
    "        self.max_steps_per_episode = max_steps_per_episode\n",
    "        self.num_episodes = num_episodes\n",
    "\n",
    "        self.train_freq = max(1, int(train_freq))\n",
    "        self.gradient_steps = max(1, int(gradient_steps))\n",
    "        self.learning_starts = int(learning_starts)\n",
    "\n",
    "        self.tau = float(tau)\n",
    "        self.target_update_freq = int(target_update_freq)\n",
    "        self._num_updates = 0\n",
    "        self._num_env_steps = 0\n",
    "\n",
    "        # ε を「ステップ単位」で減衰\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.epsilon_decay_steps = max(1, int(epsilon_decay_steps))\n",
    "\n",
    "        # リプレイバッファ\n",
    "        self.replay_buffer = ReplayBufferCls(memory_size)\n",
    "\n",
    "        # 事前収集\n",
    "        self._init_replay_buffer()\n",
    "\n",
    "        self.rewards: List[float] = []\n",
    "        self.losses: List[float] = []\n",
    "\n",
    "    # =====================\n",
    "    # 公開 API\n",
    "    # =====================\n",
    "    def train(self) -> Dict[str, List[float]]:\n",
    "        pbar = tqdm.tqdm(total=self.num_episodes, desc=\"Train Double DQN\")\n",
    "        for ep in range(self.num_episodes):\n",
    "            ep_reward = self._run_episode(ep)\n",
    "            self.rewards.append(ep_reward)\n",
    "\n",
    "            last_loss = self.losses[-1] if self.losses else float(\"nan\")\n",
    "            pbar.set_postfix_str(f\"EpR: {ep_reward:.2f}  Loss: {last_loss:.3f}  ε: {self._epsilon_by_step(self._num_env_steps):.3f}\")\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "        return {\"rewards\": self.rewards, \"losses\": self.losses}\n",
    "\n",
    "    # =====================\n",
    "    # エピソード実行\n",
    "    # =====================\n",
    "    def _run_episode(self, episode_idx: int) -> float:\n",
    "        env = Othello()\n",
    "        total_reward = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        while not env.is_terminal() and steps < self.max_steps_per_episode:\n",
    "            epsilon = self._epsilon_by_step(self._num_env_steps)\n",
    "\n",
    "            # ★ここで事前に現在盤面をコピー（観測 s）\n",
    "            board_before = copy.deepcopy(env.board)\n",
    "            player = env.player\n",
    "\n",
    "            action = self._select_action_by_epsilon_greedy(env, epsilon)\n",
    "\n",
    "            # 1 ステップ進める\n",
    "            if action == 64:\n",
    "                env.player = -player\n",
    "            else:\n",
    "                r, c = self._action_to_rc(action)\n",
    "                env.play(r, c, player)\n",
    "\n",
    "            reward = self.compute_reward(env, player)\n",
    "            done = env.is_terminal()\n",
    "\n",
    "            # ★board_before を保存（s）\n",
    "            self._store_transition(\n",
    "                board=board_before,\n",
    "                action=action,\n",
    "                reward=reward,\n",
    "                next_board=env.board,  # s'\n",
    "                done=done,\n",
    "                player=player,\n",
    "                next_player=env.player,\n",
    "                force_read_prev_from_env=False,\n",
    "            )\n",
    "\n",
    "            # 学習（一定間隔・ウォームアップ後）\n",
    "            if (self._num_env_steps % self.train_freq == 0) and (len(self.replay_buffer) >= max(self.batch_size, self.learning_starts)):\n",
    "                for _ in range(self.gradient_steps):\n",
    "                    loss = self._update_dqn_double()\n",
    "                    if not math.isnan(loss):\n",
    "                        self.losses.append(loss)\n",
    "\n",
    "            # ターゲット更新\n",
    "            self._maybe_update_target()\n",
    "\n",
    "            total_reward += float(Reward(player).get_reward(env))\n",
    "            steps += 1\n",
    "            self._num_env_steps += 1\n",
    "\n",
    "        return float(total_reward)\n",
    "\n",
    "    # =====================\n",
    "    # Double DQN アップデート\n",
    "    # =====================\n",
    "    def _update_dqn_double(self) -> float:\n",
    "        batch = self.replay_buffer.sample(self.batch_size)\n",
    "\n",
    "        # (B,1,8,8)\n",
    "        board = torch.stack([self._to_1x8x8(b['board']) for b in batch]).to(self.device)\n",
    "        next_board = torch.stack([self._to_1x8x8(b['next_board']) for b in batch]).to(self.device)\n",
    "\n",
    "        action = torch.tensor([b['action'] for b in batch], dtype=torch.int64, device=self.device)\n",
    "        reward = torch.tensor([b['reward'] for b in batch], dtype=torch.float32, device=self.device)\n",
    "        done = torch.tensor([b['done'] for b in batch], dtype=torch.float32, device=self.device)\n",
    "        player = torch.tensor([b['player'] for b in batch], dtype=torch.int64, device=self.device)\n",
    "        next_player = torch.tensor([b['next_player'] for b in batch], dtype=torch.int64, device=self.device)\n",
    "        next_legal_actions_list = [b['next_legal_actions'] for b in batch]\n",
    "\n",
    "        # Q(s,a)（現在ネット）\n",
    "        q_all = self.dqn(board)                                 # (B,65)\n",
    "        q_sa = q_all.gather(1, action.unsqueeze(1)).squeeze(1)  # (B,)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # --- Double DQN: オンラインで argmax（次状態） ---\n",
    "            # 合法手マスク（次状態用）\n",
    "            next_masks = self._build_masks_from_indices(next_legal_actions_list)  # (B,65) with 0 or -inf\n",
    "            q_next_online = self.dqn(next_board) + next_masks\n",
    "            next_actions_online = q_next_online.argmax(dim=1)  # (B,)\n",
    "\n",
    "            # ターゲットで評価\n",
    "            q_next_target = self.target_dqn(next_board)\n",
    "            next_q = q_next_target.gather(1, next_actions_online.unsqueeze(1)).squeeze(1)  # (B,)\n",
    "\n",
    "            target = reward + self.gamma * next_q * (1.0 - done)\n",
    "\n",
    "        # 損失と更新\n",
    "        loss = self.loss_fn(q_sa, target)\n",
    "        if torch.isnan(loss):\n",
    "            return float(\"nan\")\n",
    "\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.dqn.parameters(), max_norm=1.0)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self._num_updates += 1\n",
    "        return float(loss.item())\n",
    "\n",
    "    # =====================\n",
    "    # 行動選択\n",
    "    # =====================\n",
    "    def _select_action_by_epsilon_greedy(self, env, epsilon: float) -> int:\n",
    "        legal_rc = env.legal_moves(env.player)\n",
    "        if len(legal_rc) == 0:\n",
    "            return 64  # パス\n",
    "\n",
    "        if random.random() < epsilon:\n",
    "            r, c = random.choice(legal_rc)\n",
    "            return self._rc_to_action(r, c)\n",
    "        return self._select_action_by_greedy(env)\n",
    "\n",
    "    def _select_action_by_greedy(self, env) -> int:\n",
    "        legal_rc = env.legal_moves(env.player)\n",
    "        if len(legal_rc) == 0:\n",
    "            return 64\n",
    "\n",
    "        board_tensor = self._to_1x8x8(env.board).unsqueeze(0).to(self.device)  # (1,1,8,8)\n",
    "        with torch.no_grad():\n",
    "            q_all = self.dqn(board_tensor).squeeze(0)  # (65,)\n",
    "            mask = torch.full((65,), float('-inf'), device=self.device)\n",
    "            for r, c in legal_rc:\n",
    "                mask[self._rc_to_action(r, c)] = 0.0\n",
    "            # 合法手があるときはパスは原則無効\n",
    "            q_masked = q_all + mask\n",
    "            action = int(q_masked.argmax().item())\n",
    "        return action\n",
    "\n",
    "    # =====================\n",
    "    # 事前収集\n",
    "    # =====================\n",
    "    def _init_replay_buffer(self):\n",
    "        target = min(self.init_memory_size, self.replay_buffer.memory_size)\n",
    "        added = 0\n",
    "        pbar = tqdm.tqdm(total=target, desc='Init replay buffer')\n",
    "        while added < target:\n",
    "            env = Othello()\n",
    "            done = False\n",
    "            while not done and added < target:\n",
    "                # _init_replay_buffer 内の while ループ\n",
    "                player = env.player\n",
    "                board_before = copy.deepcopy(env.board)   # ★ここ\n",
    "                legal_actions = env.legal_moves(player)\n",
    "                if len(legal_actions) == 0:\n",
    "                    action = 64\n",
    "                    env.player = -player\n",
    "                else:\n",
    "                    r, c = random.choice(legal_actions)\n",
    "                    action = self._rc_to_action(r, c)\n",
    "                    env.play(r, c, player)\n",
    "\n",
    "                reward = self.compute_reward(env, player)\n",
    "                done = env.is_terminal()\n",
    "                self._store_transition(\n",
    "                    board=board_before,\n",
    "                    action=action,\n",
    "                    reward=reward,\n",
    "                    next_board=env.board,\n",
    "                    done=done,\n",
    "                    player=player,\n",
    "                    next_player=env.player,\n",
    "                    force_read_prev_from_env=False,\n",
    "                )\n",
    "                added += 1\n",
    "                pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    # =====================\n",
    "    # ターゲット更新\n",
    "    # =====================\n",
    "    def _maybe_update_target(self):\n",
    "        if self.tau and self.tau > 0.0:\n",
    "            # Polyak\n",
    "            with torch.no_grad():\n",
    "                for tp, p in zip(self.target_dqn.parameters(), self.dqn.parameters()):\n",
    "                    tp.data.mul_(1.0 - self.tau).add_(self.tau * p.data)\n",
    "        else:\n",
    "            # ハード\n",
    "            if (self._num_updates % max(1, self.target_update_freq)) == 0 and self._num_updates > 0:\n",
    "                self.target_dqn.load_state_dict(self.dqn.state_dict())\n",
    "\n",
    "    # =====================\n",
    "    # ε スケジュール（ステップ）\n",
    "    # =====================\n",
    "    def _epsilon_by_step(self, step: int) -> float:\n",
    "        # 線形減衰（終端で epsilon_end にクリップ）\n",
    "        if step >= self.epsilon_decay_steps:\n",
    "            return self.epsilon_end\n",
    "        span = self.epsilon_start - self.epsilon_end\n",
    "        return self.epsilon_start - span * (step / self.epsilon_decay_steps)\n",
    "\n",
    "    # =====================\n",
    "    # マスク生成\n",
    "    # =====================\n",
    "    def _build_legal_action_masks(self, boards: torch.Tensor, players: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        boards: (B,1,8,8) on device\n",
    "        players: (B,)\n",
    "        return: (B,65) 0 or -inf\n",
    "        \"\"\"\n",
    "        B = boards.shape[0]\n",
    "        masks = torch.full((B, 65), float('-inf'), device=boards.device)\n",
    "        # バッチで Othello を都度立て直す（環境が軽い前提）\n",
    "        for i in range(B):\n",
    "            env_tmp = Othello()\n",
    "            env_tmp.board = boards[i].squeeze(0).detach().cpu().numpy().tolist()\n",
    "            env_tmp.player = int(players[i].item())\n",
    "            legal_rc = env_tmp.legal_moves(env_tmp.player)\n",
    "            if len(legal_rc) == 0:\n",
    "                masks[i, 64] = 0.0\n",
    "            else:\n",
    "                for r, c in legal_rc:\n",
    "                    masks[i, self._rc_to_action(r, c)] = 0.0\n",
    "        return masks\n",
    "\n",
    "    # =====================\n",
    "    # 低レベル補助\n",
    "    # =====================\n",
    "    def _action_to_rc(self, action: int) -> Tuple[int, int]:\n",
    "        return divmod(int(action), 8)\n",
    "\n",
    "    def _rc_to_action(self, row: int, col: int) -> int:\n",
    "        return row * 8 + col\n",
    "\n",
    "    def _to_1x8x8(self, board) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        入力を (1,8,8) tensor に正規化（その後 Stack で (B,1,8,8) になる想定）\n",
    "        \"\"\"\n",
    "        if board is None:\n",
    "            # フォールバック（ありえない場合は呼び出し元で直近盤面を再採取）\n",
    "            board = [[0]*8 for _ in range(8)]\n",
    "        t = torch.as_tensor(board, dtype=torch.float32)\n",
    "        if t.dim() == 2 and t.shape == (8, 8):\n",
    "            t = t.unsqueeze(0)\n",
    "        elif t.dim() == 4 and t.shape[1:] == (1, 8, 8):\n",
    "            t = t.squeeze(1)\n",
    "        elif t.dim() == 3 and t.shape == (1, 8, 8):\n",
    "            pass\n",
    "        else:\n",
    "            t = t.reshape(1, 8, 8)[0:1]\n",
    "        return t\n",
    "\n",
    "    def compute_reward(self, next_env, player: int) -> float:\n",
    "        try:\n",
    "            r = Reward(player).get_reward(next_env)\n",
    "        except Exception:\n",
    "            r = 0.0\n",
    "        return float(r)\n",
    "\n",
    "    def _store_transition(\n",
    "        self,\n",
    "        board,\n",
    "        action: int,\n",
    "        reward: float,\n",
    "        next_board,\n",
    "        done: bool,\n",
    "        player: int,\n",
    "        next_player: int,\n",
    "        force_read_prev_from_env: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        board / next_board は (8x8) 互換配列 or (1,8,8) 互換で OK\n",
    "        \"\"\"\n",
    "        env_tmp = Othello()\n",
    "        env_tmp.board = board\n",
    "        env_tmp.player = player\n",
    "        legal_rc = env_tmp.legal_moves(next_player)\n",
    "\n",
    "        if len(legal_rc) == 0:\n",
    "            next_player_actions = [64]\n",
    "        else:\n",
    "            next_player_actions = [self._rc_to_action(r, c) for r, c in legal_rc]\n",
    "        # 一部の Othello 実装は「直前盤面」を持たない想定があるので、必要なら再取得\n",
    "\n",
    "        transition = {\n",
    "            \"board\": self._to_1x8x8(board),\n",
    "            \"action\": int(action),\n",
    "            \"reward\": float(reward),\n",
    "            \"next_board\": self._to_1x8x8(next_board),\n",
    "            \"done\": bool(done),\n",
    "            \"player\": int(player),\n",
    "            \"next_player\": int(next_player),\n",
    "            \"next_legal_actions\": next_player_actions,\n",
    "        }\n",
    "        self.replay_buffer.append(transition)\n",
    "\n",
    "    def _build_masks_from_indices(self, batch_next_legal_actions):\n",
    "        \"\"\"\n",
    "        batch_next_legal_actions: (B,) of list[int]\n",
    "        return: (B,65)\n",
    "        \"\"\"\n",
    "        B = len(batch_next_legal_actions)\n",
    "        masks = torch.full((B, 65), float('-inf'), device=self.device)\n",
    "        for i, acts in enumerate(batch_next_legal_actions):\n",
    "            for a in acts:\n",
    "                masks[i, a] = 0.0\n",
    "        return masks\n",
    "\n",
    "    def _safe_copy_board(self, env, previous=False):\n",
    "        \"\"\"\n",
    "        一部の環境で前盤面を保持している場合だけ使うための安全コピー\n",
    "        \"\"\"\n",
    "        if previous and hasattr(env, \"prev_board\"):\n",
    "            return copy.deepcopy(env.prev_board)\n",
    "        return copy.deepcopy(env.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d8eb093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Init replay buffer: 100%|██████████| 5000/5000 [00:02<00:00, 2469.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_memory_size = 5000 memory_size = 50000\n",
      "len(memory) before = 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dqn = DQN()\n",
    "train_dqn = TrainDoubleDQN(dqn, ReplayBufferCls=ReplayBuffer)\n",
    "print(\"init_memory_size =\", train_dqn.init_memory_size, \"memory_size =\", train_dqn.replay_buffer.memory_size)\n",
    "print(\"len(memory) before =\", len(train_dqn.replay_buffer.memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2009d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done count = 83 / 5000 0.0166\n"
     ]
    }
   ],
   "source": [
    "memory = train_dqn.replay_buffer.memory\n",
    "list_done = [m['done'] for m in memory]\n",
    "print(\"done count =\", list_done.count(True), \"/\", len(list_done), list_done.count(True) / len(list_done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c52fdaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Init replay buffer: 100%|██████████| 5000/5000 [00:01<00:00, 2712.39it/s]\n",
      "Train Double DQN:  12%|█▏        | 1240/10000 [30:14<3:51:06,  1.58s/it, EpR: -3.27  Loss: 0.091  ε: 0.050]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     17\u001b[39m dqn = DQN()\n\u001b[32m     19\u001b[39m trainer = TrainDoubleDQN(\n\u001b[32m     20\u001b[39m     dqn,\n\u001b[32m     21\u001b[39m     device=device,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     ReplayBufferCls=replay_buffer_cls,\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m res = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m rewards = res[\u001b[33m\"\u001b[39m\u001b[33mrewards\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mTrainDoubleDQN.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     90\u001b[39m pbar = tqdm.tqdm(total=\u001b[38;5;28mself\u001b[39m.num_episodes, desc=\u001b[33m\"\u001b[39m\u001b[33mTrain Double DQN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_episodes):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     ep_reward = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.rewards.append(ep_reward)\n\u001b[32m     95\u001b[39m     last_loss = \u001b[38;5;28mself\u001b[39m.losses[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.losses \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mTrainDoubleDQN._run_episode\u001b[39m\u001b[34m(self, episode_idx)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._num_env_steps % \u001b[38;5;28mself\u001b[39m.train_freq == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.replay_buffer) >= \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m.batch_size, \u001b[38;5;28mself\u001b[39m.learning_starts)):\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.gradient_steps):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_dqn_double\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m math.isnan(loss):\n\u001b[32m    145\u001b[39m             \u001b[38;5;28mself\u001b[39m.losses.append(loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 195\u001b[39m, in \u001b[36mTrainDoubleDQN._update_dqn_double\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(loss):\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m loss.backward()\n\u001b[32m    197\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.dqn.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/othello-with-rl/rl_agent/.venv/lib/python3.12/site-packages/torch/_compile.py:41\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mThis API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03mtorch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03mthe invocation of the decorated function.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     43\u001b[39m         \u001b[38;5;66;03m# cache this on the first invocation to avoid adding too much overhead.\u001b[39;00m\n\u001b[32m     44\u001b[39m         disable_fn = \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[33m\"\u001b[39m\u001b[33m__dynamo_disable\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# デバイスの設定\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "num_episodes = 10000\n",
    "gamma = 0.99\n",
    "lr = 5e-4\n",
    "target_update_freq = 2000\n",
    "batch_size = 128\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.05\n",
    "epsilon_decay_steps = 20000\n",
    "\n",
    "replay_buffer_cls = ReplayBuffer\n",
    "\n",
    "dqn = DQN()\n",
    "\n",
    "trainer = TrainDoubleDQN(\n",
    "    dqn,\n",
    "    device=device,\n",
    "    num_episodes=num_episodes,\n",
    "    gamma=gamma,\n",
    "    lr=lr,\n",
    "    target_update_freq=target_update_freq,\n",
    "    batch_size=batch_size,\n",
    "    epsilon_start=epsilon_start,\n",
    "    epsilon_end=epsilon_end,\n",
    "    epsilon_decay_steps=epsilon_decay_steps,\n",
    "    ReplayBufferCls=replay_buffer_cls,\n",
    ")\n",
    "\n",
    "res = trainer.train()\n",
    "rewards = res[\"rewards\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bcc741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e6a45",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
